{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>MDI343 - TP Text Mining - Alexandre Durand - 2017/2018</center>  \n",
    "# <center>Application à la classification : l’Analyse d’opinions</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset\n",
      "2000 documents\n"
     ]
    }
   ],
   "source": [
    "# Authors: Alexandre Gramfort\n",
    "#          Chloe Clavel\n",
    "# License: BSD Style.\n",
    "# TP Cours ML Telecom ParisTech MDI343\n",
    "\n",
    "import os.path as op\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from time import time\n",
    "\n",
    "\n",
    "# Load data\n",
    "print(\"Loading dataset\")\n",
    "\n",
    "from glob import glob\n",
    "filenames_neg = sorted(glob(op.join('.', 'data', 'imdb1', 'neg', '*.txt')))\n",
    "filenames_pos = sorted(glob(op.join('.', 'data', 'imdb1', 'pos', '*.txt')))\n",
    "\n",
    "texts_neg = [open(f).read() for f in filenames_neg]\n",
    "texts_pos = [open(f).read() for f in filenames_pos]\n",
    "texts = texts_neg + texts_pos\n",
    "y = np.ones(len(texts), dtype=np.int)\n",
    "y[:len(texts_neg)] = 0\n",
    "\n",
    "print(\"%d documents\" % len(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implémentation du classifieur\n",
    "***\n",
    "\n",
    "### Questions 1:\n",
    "\n",
    "#### Compléter la fonction $count\\_words$ qui va compter le nombre d’occurrences de chaque mot dans une liste de string et renvoyer le vocabulaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_words(texts):\n",
    "    \"\"\"Vectorize text : return count of each word in the text snippets\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    texts : list of str\n",
    "        The texts\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    vocabulary : dict\n",
    "        A dictionary that points to an index in counts for each word.\n",
    "    counts : ndarray, shape (n_samples, n_features)\n",
    "        The counts of each word in each text.\n",
    "        n_samples == number of documents.\n",
    "        n_features == number of words in vocabulary.\n",
    "    \"\"\"\n",
    "    # Construction d'un ensemble (un 'set') du vocabulaire\n",
    "    words = set()\n",
    "    for text in texts:\n",
    "        for w in text.split():\n",
    "            words.add(w.strip())\n",
    "\n",
    "    # Construction d'un dictionnaire {word : index of the word}\n",
    "    n_features = len(words)\n",
    "    dict_w_idx = dict(zip(words, range(n_features)))\n",
    "\n",
    "    # Creation et Remplissage de la matrice \"counts\" (généralement appelée: X)\n",
    "    counts = np.zeros((len(texts), n_features))\n",
    "\n",
    "    for i, text in enumerate(texts):\n",
    "        for w in text.split():\n",
    "            j = dict_w_idx[w.strip()]\n",
    "            counts[i, j] = counts[i, j] + 1\n",
    "\n",
    "    return dict_w_idx, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (count_words : execution time = 1.87 s)\n",
      "Taille du Vocabulaire = 50920\n",
      "Taille de la matrice X = (2000, 50920)\n"
     ]
    }
   ],
   "source": [
    "# Test de la fonction \"count_words\" sur le corpus entier\n",
    "start = time()\n",
    "\n",
    "vocabulary, X = count_words(texts)\n",
    "\n",
    "print(\" (count_words : execution time = %0.2f s)\" % (time() - start))\n",
    "print(\"Taille du Vocabulaire =\", len(vocabulary))\n",
    "print(\"Taille de la matrice X =\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.\n",
    "#### Expliquer comment les classes positives et négatives ont été assignées sur les critiques de films (voir fichier poldata.README.2.0)\n",
    "\n",
    "> Pour déterminer si une critique était positive ou négative, comme aucune notation n'était accessible via un format structuré, les auteurs du fichier ont recherché des indications dans le texte. Cela pouvait être, entre autres, des notations numériques du type (8/10) ou via un système d'étoiles (3 étoiles sur 5).\n",
    "\n",
    "> Les règles suivantes ont ensuite été appliquées :  \n",
    "- Sur une échelle de $0$ à $5$ :\n",
    "    - Note $\\ \\geqslant \\ 3.5 \\ / \\ 5  \\ \\ \\Longrightarrow$ critique positive\n",
    "    - Note $\\ \\leqslant \\ \\ \\ \\ 2 \\ / \\ 5 \\ \\ \\Longrightarrow$ critique négative  \n",
    "\n",
    ">  \n",
    "- Sur une échelle de $0$ à $4$ :\n",
    "    - Note $\\ \\geqslant \\ \\ \\ \\ 3 \\ / \\ 4 \\ \\ \\Longrightarrow$ critique positive\n",
    "    - Note $\\ \\leqslant \\ 1.5 \\ / \\ 5  \\ \\ \\Longrightarrow$ critique negative  \n",
    "    \n",
    ">  \n",
    "- Avec un système de lettres :\n",
    "    - Note $\\ \\geqslant \\ B \\ \\ \\ \\ \\Longrightarrow$ critique positive\n",
    "    - Note $\\ \\leqslant \\ C^- \\ \\Longrightarrow$ critique negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.\n",
    "#### Compléter la classe $NB$ pour qu’elle implémente le classifieur Naive Bayes en vous appuyant sur le pseudo-code de la figure 1 et sa documentation.  \n",
    "Explications pour la méthode $fit$ :\n",
    "> Le choix a été fait d'intégrer la fonction $count\\_words$ à l'intérieur de la méthode $fit$.\n",
    "> Ainsi le $fit$ de notre classe $NB$ prendra directement en arguments le corpus de textes d'apprentissage ainsi que les labels associés. \n",
    "\n",
    "> En sortie, on obtiendra :\n",
    "- $C$, l'ensemble des différentes classes\n",
    "- $Vocabulary\\_train$, le Vocabulaire du corpus d'entrainement\n",
    "- $prior$, la matrice des probabilités \"à priori\"\n",
    "- $condProb$, la matrice des probabilités conditionnelles d'apparation des termes en fonction de la classe\n",
    "\n",
    "Explications pour la méthode $predict$ :\n",
    "> Là encore, on donnera un texte (ou un corpus de textes) à prédire directement en entrée de la méthode.  \n",
    "Un $count\\_words$ sur ces textes nous permettra de récupèrerer le \"vocabulaire_test\" associé. Après intersection des deux vocabulaires \"Train\" et \"Test\", on réduira les matrices $condProb$ (issu de la méthode $fit$) et $X\\_test$ aux termes communs afin de pouvoir faire le produit matriciel ci-dessous, nécessaire au calcul des scores de chaque classe : $$scores = \\mathit{log} \\ prior + X\\_test \\cdot (\\mathit{log} \\ condProb)^{T}$$  \n",
    "\n",
    "> En sortie, on obtiendra :\n",
    "- $y\\_pred$, le vecteur des prédictions des textes données en entrée  \n",
    "\n",
    "> L'avantage de cette implémentation réside dans le fait qu'on n'est pas contraint de fournir des matrices $X\\_train$ et $X\\_test$ ayant le même nombre de colonnes (c'est-à-dire issu du même Vocubulaire).\n",
    "\n",
    "Explications pour la méthode $score$ :\n",
    "> Pour un corpus de textes à prédire et un vecteur contenant les vrais labels des textes, la méthode $score$ renvoie un score de prédiction qui est le rapport entre le nombre de textes qui ont été bien prédits et le nombre total de textes qu'il fallait prédire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NB(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, texts_train, y_train):\n",
    "\n",
    "        # Etape préliminaire de Count_Word\n",
    "        vocabulary_train, X_train = count_words(texts_train)\n",
    "\n",
    "        V = X_train.shape[1]  # taille du Vocabulaire Train\n",
    "        N = X_train.shape[0]  # Nbre total de Documents (= len(y_train))\n",
    "        C = np.unique(y_train)  # Ensemble des Classes\n",
    "\n",
    "        # Initialisation des matrices de calcul\n",
    "        prior = np.zeros(len(C))\n",
    "        T_ct = np.zeros((len(C), V))\n",
    "        condProb = np.zeros((len(C), V))\n",
    "\n",
    "        # Remplissage des matrices, classe par classe\n",
    "        for idx, c in enumerate(C):\n",
    "            # Probabilités \"à priori\"\n",
    "            Nc = len(y_train[y_train == c]) / N\n",
    "            prior[idx] = Nc\n",
    "\n",
    "            # Matrice T_ct (occurrence totale par classe, pour chacun des termes)\n",
    "            T_ct[idx, :] = np.sum(X_train[y_train == c, :], axis=0)\n",
    "\n",
    "            # Matrice cond_prob avec Lissage de Laplace\n",
    "            alpha = 1\n",
    "            T_ct_total = np.sum(T_ct[idx, :] + alpha)\n",
    "            condProb[idx, :] = (T_ct[idx, :] + alpha) / T_ct_total\n",
    "\n",
    "        self.C = C\n",
    "        self.vocabulary_train = vocabulary_train\n",
    "        self.prior = prior\n",
    "        self.condProb = condProb\n",
    "        return self\n",
    "\n",
    "    def predict(self, texts_test):\n",
    "\n",
    "        # Count_Words & initialisation\n",
    "        self.vocabulary_test, X_test = count_words(texts_test)\n",
    "        y_pred = np.zeros(X_test.shape[0])\n",
    "\n",
    "        # Intersection des deux \"Vocabulary\" Train & Test\n",
    "        shared_terms = self.vocabulary_train.keys() & self.vocabulary_test.keys()\n",
    "\n",
    "        # Pour chacun des 2 dictionnaires (train & test), trouver les indices des termes communs\n",
    "        idx_toKeep_train = []\n",
    "        idx_toKeep_test = []\n",
    "        for t in shared_terms:\n",
    "            idx_toKeep_train.append(self.vocabulary_train[t])\n",
    "            idx_toKeep_test.append(self.vocabulary_test[t])\n",
    "\n",
    "        # Réduction de la matrice condProb aux termes communs\n",
    "        reduced_condProb = self.condProb[:, idx_toKeep_train]\n",
    "\n",
    "        # Réduction de la matrice X_test aux termes communs\n",
    "        reduced_X_test = X_test[:, idx_toKeep_test]\n",
    "\n",
    "        # Calcul des scores = log prior + reduced_X_test.(log reduced_condProb)^T\n",
    "        log_reduced_condProb = np.log(reduced_condProb)\n",
    "        log_prior = np.log(self.prior)\n",
    "        scores = log_prior + np.dot(reduced_X_test, log_reduced_condProb.T)\n",
    "\n",
    "        # Prediction = classe qui a le plus grand score\n",
    "        maxScore = np.argmax(scores, axis=1)\n",
    "        y_pred = self.C[maxScore]\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def score(self, texts_test, y_test):\n",
    "        return np.mean(self.predict(texts_test) == y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.\n",
    "#### Evaluer les performances de votre classifieur en cross-validation 5-folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.815 (+/- 0.027)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    8.4s finished\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(NB(), texts, y, cv=5, n_jobs=-1, verbose=1)\n",
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (cv_scores.mean(), cv_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5.\n",
    "#### Modifiez la fonction $count\\_words$ pour qu’elle ignore les “stop words” dans le fichier *data/english.stop*. Les performances sont-elles améliorées ?\n",
    "\n",
    "Explications :\n",
    "> Comme nous utilisons la fonction $count\\_words$ dans la classe $NB$, plutôt que de modifier la fonction $count\\_words$ elle-même (ce qui impliquerait de recréer une classe $NB$ avec cette nouvelle fonction), nous allons plutôt retirer les \"stop words\" directement dans le corpus de textes.  \n",
    "\n",
    "> C'est ce que fait la fonction $retrieve\\_stopW$ ci-dessous, qui prend en argument une liste de textes ainsi qu'un ensemble de \"stop words\" et retourne une nouvelle liste de ces mêmes textes mais sans les \"stop words\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve_stopW(texts, stopWords):\n",
    "    texts_cleaned = []\n",
    "    for text in texts:\n",
    "        text_cleaned = [w.strip() for w in text.split() if w.strip() not in stopWords]\n",
    "        texts_cleaned.append(\" \".join(text_cleaned))\n",
    "    return texts_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lecture du fichier de stop_words\n",
    "english_StopWords = set(open('./data/english.stop').read().split('\\n'))\n",
    "\n",
    "# Nettoyage des \"stop words\" dans le corpus\n",
    "texts_cleaned = retrieve_stopW(texts, english_StopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'count_words' sur le corpus de textes sans les 'stop words' (par rapport à avec) :\n",
      "==> Nombre de termes uniques (features) en moins = 545 (soit 1.07%)\n",
      "==> Nombre d'occurrences en moins = 718127 (soit 48.11%)\n"
     ]
    }
   ],
   "source": [
    "# Comparaison avec le corpus de textes initial (i.e. avec les \"stop words\")\n",
    "vocabulary, X = count_words(texts)\n",
    "vocabulary_cleaned, X_cleaned = count_words(texts_cleaned)\n",
    "\n",
    "print(\"'count_words' sur le corpus de textes sans les 'stop words' (par rapport à avec) :\")\n",
    "\n",
    "diff_feat = len(vocabulary) - len(vocabulary_cleaned)\n",
    "p_diff_feat = diff_feat * 100 / len(vocabulary)\n",
    "print(\"==> Nombre de termes uniques (features) en moins =\", diff_feat,\n",
    "      \"(soit %0.2f\" % p_diff_feat + \"%)\")\n",
    "\n",
    "diff_occur = X.sum() - X_cleaned.sum()\n",
    "p_diff_occur = diff_occur * 100 / X.sum()\n",
    "print(\"==> Nombre d'occurrences en moins = %d\" % diff_occur,\n",
    "      \"(soit %0.2f\" % p_diff_occur + \"%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.805 (+/- 0.025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    9.3s finished\n"
     ]
    }
   ],
   "source": [
    "# Evaluation des performances sans les 'stop words'\n",
    "cv_scores = cross_val_score(NB(), texts_cleaned, y, cv=5, n_jobs=-1, verbose=1)\n",
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (cv_scores.mean(), cv_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Conclusion :**\n",
    "> En retirant les 'stop words', le score est sensiblement identique à celui calculé précédemment sur les textes originaux.\n",
    "\n",
    "> Ce résultat semble assez logique si on fait l'hypothèse, plutôt réaliste, qu'il y a autant de 'stop words' dans les critiques positives que dans les critiques négatives. La présence ou non de ces mots n'a donc peu d'influence dans le choix du label à prédire.\n",
    "\n",
    "> Les mots véritablement discrimants sont ceux qui sont présents en plus grande majorité dans les textes d'un label plutôt que d'un autre.\n",
    "\n",
    "> Par contre, l'avantage de ne pas inclure les 'stop words' se trouve dans la taille réduite des objets à manipuler.\n",
    "En comparant les résultats d'un $count\\_words$ sur le corpus original et sur le corpus dont les 'stop words' ont été retirés, on se rend compte qu'on a retirés pratiquement 50% des occurences, tous termes confondus.  \n",
    "Si on devait traiter une masse de textes beaucoup plus imposante, cela aurait peut-être une influence siginificative sur les temps de calcul."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilisation de scikitlearn\n",
    "***\n",
    "\n",
    "### Questions 1.\n",
    "\n",
    "#### Comparer votre implémentation avec scikitlearn.\n",
    "\n",
    "On utilisera la classe CountVectorizer et un Pipeline.\n",
    "\n",
    "Vous expérimenterez en autorisant les mots et bigrammes ou en travaillant sur les sous-chaines de caractères (option analyzer='char')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Avant d'expérimenter sur les mots et les bigrammes, nous allons utiliser une première fois le classifieur de ScikitLearn en utilisant seulement les mots (comme nous avons fait jusqu'à présent) afin d'avoir un point de comparaison entre les différentes méthodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.812 (+/- 0.026)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.1s finished\n"
     ]
    }
   ],
   "source": [
    "# Travail sur les mots seulement :  analyzer='word' & ngram_range=(1, 1)\n",
    "# --------------------------------\n",
    "vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 1))\n",
    "multiNB = MultinomialNB()\n",
    "pipeline = Pipeline([(\"vectorizer\", vectorizer), (\"multiNB\", multiNB)])\n",
    "\n",
    "# Evaluate the models using crossvalidation\n",
    "cv_scores = cross_val_score(pipeline, texts, y, cv=5, n_jobs=-1, verbose=1)\n",
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (cv_scores.mean(), cv_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion :**\n",
    "\n",
    "> Le classifieur de scikitlearn réalise une performance similaire à notre classifieur (légèrement plus faible même) mais en un temps d'execution plus rapide, surement dû aux optimisations computationnelles propres à SKLearn.  \n",
    "\n",
    "Nous allons maintenant effectuer la classification en prenant en compte à la fois les mots mais aussi les bigrammes (ensemble formé par un mot + le mot qui le précède)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.831 (+/- 0.019)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   15.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Travail sur les mots et les bigrammes :  analyzer='word' & ngram_range=(1, 2)\n",
    "# --------------------------------------\n",
    "vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 2))\n",
    "multiNB = MultinomialNB()\n",
    "pipeline = Pipeline([(\"vectorizer\", vectorizer), (\"multiNB\", multiNB)])\n",
    "\n",
    "# Evaluate the models using crossvalidation\n",
    "cv_scores = cross_val_score(pipeline, texts, y, cv=5, n_jobs=-1, verbose=1)\n",
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (cv_scores.mean(), cv_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion :**\n",
    "> L'utilisation des mots et bigrammes a permis une nette amélioration du score (pratiquement 3%).  \n",
    "\n",
    "> Cela prouve qu'au delà du sens d'un mot, c'est bien des ensembles de mots qui apportent de l'information utile à la classification.\n",
    "\n",
    "> Voyons si des ensembles de mots plus longs n'apporteraient pas plus d'informations. Nous allons utiliser une \"GridSearch\" pour cela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram_range used : (1, 1)   -->  score = 0.812\n",
      "ngram_range used : (1, 2)   -->  score = 0.831\n",
      "ngram_range used : (1, 3)   -->  score = 0.823\n",
      "ngram_range used : (1, 4)   -->  score = 0.817\n",
      "ngram_range used : (1, 5)   -->  score = 0.814\n",
      "ngram_range used : (1, 6)   -->  score = 0.810\n",
      "\n",
      "Best Candidate:\n",
      "   Best Score : 0.831\n",
      "   Best Parameters : (1, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Pipeline and Parameters\n",
    "vectorizer = CountVectorizer(analyzer='word')\n",
    "multiNB = MultinomialNB()\n",
    "pipeline = Pipeline([(\"vectorizer\", vectorizer), (\"multiNB\", multiNB)])\n",
    "\n",
    "parameters = {'vectorizer__ngram_range':[(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (1, 6)]}\n",
    "\n",
    "# Fit the Grid Search\n",
    "grid = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=0)\n",
    "grid.fit(texts, y)\n",
    "\n",
    "# Display Results\n",
    "mean_scores = grid.cv_results_['mean_test_score']\n",
    "for i in range(len(mean_scores)):\n",
    "    print(\"ngram_range used :\", grid.cv_results_['params'][i]['vectorizer__ngram_range'],\n",
    "          \"  -->  score = %0.3f\" % mean_scores[i])\n",
    "\n",
    "print(\"\\nBest Candidate:\")\n",
    "print(\"   Best Score : %0.3f\" % grid.best_score_)\n",
    "print(\"   Best Parameters :\", grid.best_params_['vectorizer__ngram_range'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion :**\n",
    "> Non, en autorisant des combinaisons encore plus complexes que la seule utilisation des mots et bigrammes, nous n'avons pas fait augmenter la performance du classifieur. Ne conserver que les mots et bigrammes semble donc un choix très judicieux.\n",
    "\n",
    "Testons maintenant en prenant en compte, non plus des mots entiers, mais seulement des sous-chaines de caractères.  \n",
    "Pour cela, on utilise le paramètre 'analyzer=char'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram_range used : (3, 3)   -->  score = 0.7645\n",
      "ngram_range used : (4, 4)   -->  score = 0.8\n",
      "ngram_range used : (5, 5)   -->  score = 0.8195\n",
      "ngram_range used : (6, 6)   -->  score = 0.8275\n",
      "ngram_range used : (7, 7)   -->  score = 0.828\n",
      "ngram_range used : (8, 8)   -->  score = 0.829\n",
      "ngram_range used : (1, 3)   -->  score = 0.7475\n",
      "ngram_range used : (1, 4)   -->  score = 0.7865\n",
      "ngram_range used : (1, 5)   -->  score = 0.804\n",
      "ngram_range used : (1, 6)   -->  score = 0.816\n",
      "ngram_range used : (1, 7)   -->  score = 0.8215\n",
      "ngram_range used : (1, 8)   -->  score = 0.818\n",
      "\n",
      "Best Candidate:\n",
      "   Best Score : 0.829\n",
      "   Best Parameters : (8, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Pipeline and Parameters\n",
    "vectorizer = CountVectorizer(analyzer='char')\n",
    "multiNB = MultinomialNB()\n",
    "pipeline = Pipeline([(\"vectorizer\", vectorizer), (\"multiNB\", multiNB)])\n",
    "\n",
    "parameters = {'vectorizer__ngram_range':[(3, 3), (4, 4), (5, 5), (6, 6), (7, 7), (8, 8),\n",
    "                                         (1, 3), (1, 4), (1, 5), (1, 6), (1, 7), (1, 8)]}\n",
    "\n",
    "# Fit the Grid Search\n",
    "grid = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1, verbose=0)\n",
    "grid.fit(texts, y)\n",
    "\n",
    "# Display Results\n",
    "mean_scores = grid.cv_results_['mean_test_score']\n",
    "for i in range(len(mean_scores)):\n",
    "    print(\"ngram_range used :\", grid.cv_results_['params'][i]['vectorizer__ngram_range'],\n",
    "          \"  -->  score =\", mean_scores[i])\n",
    "\n",
    "print(\"\\nBest Candidate:\")\n",
    "print(\"   Best Score :\", grid.best_score_)\n",
    "print(\"   Best Parameters :\", grid.best_params_['vectorizer__ngram_range'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Conclusion :**\n",
    "> Le meilleur score est obtenu en travaillant sur des sous-chaines de 8 caractères. \n",
    "\n",
    "> Ce score est assez proche de celui trouvé précédemment (travail sur les mots & bigrammes, score = 0.831). Ce n'est pas illogique, la taille d'un mot ou d'un ensemble de 2 mots doit probablement s'approcher de ce nombre de caractères.\n",
    "\n",
    "> Bien que très proche, ce score est malgré tout inférieur au meilleur score obtenu en travaillant sur les mots entiers. Nous allons donc poursuivre les tests en ne considérant que les mots & bigrammes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions 2.\n",
    "\n",
    "#### Tester un autre algorithme de la librairie scikitlearn (ex : $LinearSVC$, $LogisticRegression$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.850 (+/- 0.039)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   22.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 2))\n",
    "linear_svc = LinearSVC(penalty='l2', loss='squared_hinge')\n",
    "pipeline = Pipeline([(\"vectorizer\", vectorizer), (\"linear_svc\", linear_svc)])\n",
    "\n",
    "# Evaluate the models using crossvalidation\n",
    "cv_scores = cross_val_score(pipeline, texts, y, cv=5, n_jobs=-1, verbose=1)\n",
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (cv_scores.mean(), cv_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.853 (+/- 0.033)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   19.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 2))\n",
    "log_regr = LogisticRegression(penalty='l2', solver='liblinear', n_jobs=-1)\n",
    "pipeline = Pipeline([(\"vectorizer\", vectorizer), (\"log_regr\", log_regr)])\n",
    "\n",
    "# Evaluate the models using crossvalidation\n",
    "cv_scores = cross_val_score(pipeline, texts, y, cv=5, n_jobs=-1, verbose=1)\n",
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (cv_scores.mean(), cv_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Conclusion :**\n",
    "> Nous avons testé deux autres algorithmes : $linearSVC$ et $LogisticRegression$.  \n",
    "\n",
    "> Les résultats sont meilleures (d'environ 2%) qu'avec notre implémentation ou encore qu'avec $MultinomialNB$ de SKLearn. Cette amélioration se paye cependant par un temps de calcul supérieur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions 3.\n",
    "\n",
    "#### Utiliser la librairie NLTK afin de procéder à une racinisation (stemming). Vous utiliserez la classe SnowballStemmer.\n",
    "\n",
    "> Comme pour le traitement des 'stop words', nous allons effectuer la racinisation sur le corpus de textes entier en amont de la classification.  \n",
    "\n",
    "> La fonction $stem\\_doc$ ci-dessous réalise ce traitement.  \n",
    "\n",
    "> De plus, nous allons continuer d'utiliser le classifieur $LogisticRegression$ sur les mots et les bigrammes, combinaison ayant fourni les meilleurs résultats jusqu'à présent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import SnowballStemmer\n",
    "\n",
    "def stem_doc(texts, language):\n",
    "    stemmer = SnowballStemmer(language)\n",
    "    texts_stem = []\n",
    "    for text in texts:\n",
    "        text_stem = [stemmer.stem(w.strip()) for w in text.split()]\n",
    "        texts_stem.append(\" \".join(text_stem))\n",
    "    return texts_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (stemming : execution time = 16.90 s)\n"
     ]
    }
   ],
   "source": [
    "# Stemming of all the texts\n",
    "start = time()\n",
    "\n",
    "texts_stem = stem_doc(texts, 'english')\n",
    "\n",
    "print(\" (stemming : execution time = %0.2f s)\" % (time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.859 (+/- 0.027)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   25.2s finished\n"
     ]
    }
   ],
   "source": [
    "# Pipeline\n",
    "vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 2))\n",
    "log_regr = LogisticRegression(penalty='l2', solver='liblinear', n_jobs=-1)\n",
    "pipeline = Pipeline([(\"vectorizer\", vectorizer), (\"log_regr\", log_regr)])\n",
    "\n",
    "# Evaluate the models using crossvalidation\n",
    "cv_scores = cross_val_score(pipeline, texts_stem, y, cv=5, n_jobs=-1, verbose=1)\n",
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (cv_scores.mean(), cv_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion :**\n",
    "> La racinisation améliore encore plus les résultats.  \n",
    "\n",
    "> En éliminant les suffixes des mots, cette méthode a pour but de regrouper des variantes morphologiques d'un mot dans une racine commune.\n",
    "\n",
    "> Le fait que les termes provenant d'une même racine (et donc normalement ayant la même signification) soient, après racinisation, considérés comme identiques permet de ne pas \"disperser\" l'influence de ces termes en différentes variantes de suffixes.\n",
    "\n",
    "> Cependant, le temps passé a effectuer la racinisation est ici considérable (pratiquement autant que pour effectuer la classification elle-même). Si l'on met en regard le gain de performance (+ 0.6 %), on peut conclure que la racinisation doit être décidée en fonction des gains de performance réels et du contexte d'utilisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions 4.\n",
    "\n",
    "#### Filtrer les mots par catégorie grammaticale (POS : Part Of Speech) et ne garder que les noms, les verbes, les adverbes et les adjectifs pour la classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici la liste des \"Part-of-Speech tags\" provenant du projet Penn Treebank, et que nous allons considérer :\n",
    "\n",
    "| NOUN                          | VERB                                          | ADVERB                      | ADJECTIVE                      |\n",
    "|:-------------------------------|:-----------------------------------------------|:-----------------------------|:--------------------------------|\n",
    "| NN --> Noun, singular or mass | VB --> Verb, base form                        | RB --> Adverb               | JJ --> Adjective               |\n",
    "| NNS --> Noun, plural          | VBD --> Verb, past tense                      | RBR --> Adverb, comparative | JJR --> Adjective, comparative |\n",
    "| NNP --> Proper noun, singular | VBG --> Verb, gerund or present participle    | RBS --> Adverb, superlative | JJS --> Adjective, superlative |\n",
    "| NNPS --> Proper noun, plural  | VBN --> Verb, past participle                 |                             |                                |\n",
    "|                               | VBP --> Verb, non-3rd person singular present |                             |                                |\n",
    "|                               | VBZ --> Verb, 3rd person singular present     |                             |                                |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nouns = ['NN', 'NNS', 'NNP', 'NNPS']\n",
    "verbs = ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "adverbs = ['RB', 'RBR', 'RBS']\n",
    "adjectives = ['JJ', 'JJR', 'JJS']\n",
    "\n",
    "tags_to_keep = set(nouns + verbs + adverbs + adjectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def keep_only_desired_tags(texts, tags_to_keep):\n",
    "    texts_tags = []\n",
    "    for text in texts:\n",
    "        tagged_words = pos_tag(word_tokenize(text))\n",
    "        desired_tags_words = [t[0] for t in tagged_words if t[1] in tags_to_keep]\n",
    "        texts_tags.append(\" \".join(desired_tags_words))\n",
    "    return texts_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (POS tag : execution time = 67.57 s)\n"
     ]
    }
   ],
   "source": [
    "# Traitement sur le corpus de textes\n",
    "start = time()\n",
    "\n",
    "texts_good_tags = keep_only_desired_tags(texts, tags_to_keep)\n",
    "\n",
    "print(\" (POS tag : execution time = %0.2f s)\" % (time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.852 (+/- 0.026)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   17.1s finished\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 2))\n",
    "log_regr = LogisticRegression(penalty='l2', solver='liblinear', n_jobs=-1)\n",
    "pipeline = Pipeline([(\"vectorizer\", vectorizer), (\"log_regr\", log_regr)])\n",
    "\n",
    "# Evaluate the models using crossvalidation\n",
    "cv_scores = cross_val_score(pipeline, texts_good_tags, y, cv=5, n_jobs=-1, verbose=1)\n",
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (cv_scores.mean(), cv_scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Conclusion :**\n",
    "\n",
    "> Le score n'est pas amélioré en ne gardant que les noms, verbes, adverbes et adjectifs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conclusion générale :\n",
    "\n",
    "- Le classifieur \"Naïve Bayes\" que nous avons implémenté possède des performances comparables à celui de ScikitLearn.\n",
    "\n",
    "- Retirer les 'stop words' n'apporte pas plus de performance car ces mots sont visiblement présents en proportions similaires entre toutes les classes.\n",
    "\n",
    "- Considérer les mots et les bigrammes est la meilleure option.\n",
    "\n",
    "- Les autres algorithmes de classification (LinearSVC et LogisticRegression) ont apporté des performances très légèrement supérieures, mais avec des temps de calcul plus longs.\n",
    "\n",
    "- Considérer comme un unique terme toutes les variantes morphologiques de ce terme (=raciniser) a permis d'accroitre les performances.\n",
    "\n",
    "- Ne garder dans le corpus que les noms, verbes, adverbes et adjectifs n'a pas permis d'amélioration. De plus, le temps de preprocessing du texte (> 1 min) est rédhibitoire."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
